from typing import Any, Dict, List, Optional, Sequence
from uuid import UUID
import time
import uuid
import contextvars # <--- Import contextvars

from judgeval.common.tracer import TraceClient, TraceSpan, Tracer, SpanType, EvaluationConfig
from judgeval.data import Example # Import Example

from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.agents import AgentAction, AgentFinish
from langchain_core.outputs import LLMResult
from langchain_core.messages.base import BaseMessage
from langchain_core.documents import Document

# --- Get context vars from tracer module ---
# Assuming tracer.py defines these and they are accessible
# If not, redefine them here or adjust import

# from judgeval.common.tracer import current_span_var
# TODO: Figure out how to handle context variables. Current solution is to keep track of current span id in Tracer class

# --- NEW __init__ ---
class JudgevalCallbackHandler(BaseCallbackHandler):
    """
    LangChain Callback Handler using run_id/parent_run_id for hierarchy.
    Manages its own internal TraceClient instance created upon first use.
    Includes verbose logging and defensive checks.
    """
    # Make all properties ignored by LangChain's callback system
    # to prevent unexpected serialization issues.
    lc_serializable = False
    lc_kwargs = {}

    # --- NEW __init__ ---
    def __init__(self, tracer: Tracer):

        self.tracer = tracer
        self._trace_client: Optional[TraceClient] = None
        self._run_id_to_span_id: Dict[UUID, str] = {}
        self._span_id_to_start_time: Dict[str, float] = {}
        self._span_id_to_depth: Dict[str, int] = {}
        self._root_run_id: Optional[UUID] = None
        self._trace_saved: bool = False # Flag to prevent actions after trace is saved

        self.executed_nodes: List[str] = [] # These last four members are only appended to and never accessed; can probably be removed but still might be useful for future reference?
        self.executed_tools: List[str] = []
        self.executed_node_tools: List[str] = []
        self.traces: List[Dict[str, Any]] = []
    # --- END NEW __init__ ---

    # --- MODIFIED _ensure_trace_client ---
    def _ensure_trace_client(self, run_id: UUID, parent_run_id: Optional[UUID], event_name: str) -> Optional[TraceClient]:
        """
        Ensures the internal trace client is initialized, creating it only once
        per handler instance lifecycle (effectively per graph invocation).
        Returns the client or None.
        """

        # If a client already exists, return it.
        if self._trace_client:
            return self._trace_client

        # If no client exists, initialize it NOW.
        trace_id = str(uuid.uuid4())
        project = self.tracer.project_name
        try:
            # Use event_name as the initial trace name, might be updated later by on_chain_start if root
            client_instance = TraceClient(
                self.tracer, trace_id, event_name, project_name=project,
                overwrite=False, rules=self.tracer.rules,
                enable_monitoring=self.tracer.enable_monitoring,
                enable_evaluations=self.tracer.enable_evaluations
            )
            self._trace_client = client_instance
            if self._trace_client:
                self._root_run_id = run_id # Assign the first run_id encountered as the tentative root
                self._trace_saved = False # Ensure flag is reset
                # Set active client on Tracer (important for potential fallbacks)
                self.tracer._active_trace_client = self._trace_client
                return self._trace_client
            else:
                return None
        except Exception as e:

            self._trace_client = None
            self._root_run_id = None
            return None

    def _start_span_tracking(
        self,
        trace_client: TraceClient,
        run_id: UUID,
        parent_run_id: Optional[UUID],
        name: str,
        span_type: SpanType = "span",
        inputs: Optional[Dict[str, Any]] = None
    ) -> None:
        """Start tracking a span, ensuring trace client exists"""

        start_time = time.time()
        span_id = str(uuid.uuid4())
        parent_span_id: Optional[str] = None
        current_depth = 0

        if parent_run_id and parent_run_id in self._run_id_to_span_id:
            parent_span_id = self._run_id_to_span_id[parent_run_id]
            if parent_span_id in self._span_id_to_depth:
                current_depth = self._span_id_to_depth[parent_span_id] + 1         

        self._run_id_to_span_id[run_id] = span_id
        self._span_id_to_start_time[span_id] = start_time
        self._span_id_to_depth[span_id] = current_depth


        # --- Set SPAN context variable ONLY for chain (node) spans (Sync version) ---
        if span_type == "chain":
            self.tracer.set_current_span(span_id)

        new_trace = TraceSpan(
            span_id=span_id,
            trace_id=trace_client.trace_id,
            parent_span_id=parent_span_id,
            function=name,
            depth=current_depth,
            created_at=start_time,
            span_type=span_type
        )

        new_trace.inputs = inputs

        trace_client.add_span(new_trace)

    def _end_span_tracking(
        self,
        trace_client: TraceClient,
        run_id: UUID,
        outputs: Optional[Any] = None,
        error: Optional[BaseException] = None
    ) -> None:
        """End tracking a span, ensuring trace client exists"""

        # Get span ID and check if it exists
        span_id = self._run_id_to_span_id.get(run_id)

        start_time = self._span_id_to_start_time.get(span_id) if span_id else None
        duration = time.time() - start_time if start_time is not None else None

        # Add exit entry (only if span was tracked)
        if span_id:
            trace_span = trace_client.span_id_to_span.get(span_id)
            if trace_span:
                trace_span.duration = duration
                trace_span.output = error if error else outputs

            # Clean up dictionaries for this specific span
            if span_id in self._span_id_to_start_time: del self._span_id_to_start_time[span_id]
            if span_id in self._span_id_to_depth: del self._span_id_to_depth[span_id]

        # Check if this is the root run ending
        if run_id == self._root_run_id:
            try:
                # Reset root run id after attempt
                self._root_run_id = None
                # Reset input storage for this handler instance

                if self._trace_client and not self._trace_saved: # Check if not already saved
                    # TODO: Check if trace_client.save needs await if TraceClient becomes async
                    trace_id, trace_data = self._trace_client.save(overwrite=self._trace_client.overwrite) # Use client's overwrite setting
                    self.traces.append(trace_data) # Leaving this in for now but can probably be removed
                    self._trace_saved = True # Set flag only after successful save
            finally:
                # --- NEW: Consolidated Cleanup Logic --- 
                # This block executes regardless of save success/failure
                # Reset root run id
                self._root_run_id = None
                # Reset input storage for this handler instance
                if self.tracer._active_trace_client == self._trace_client:
                    self.tracer._active_trace_client = None
                # --- End Cleanup Logic ---

    # --- Callback Methods ---
    # Each method now ensures the trace client exists before proceeding

    def on_retriever_start(self, serialized: Dict[str, Any], query: str, *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any:
        serialized_name = serialized.get('name', 'Unknown') if serialized else "Unknown (Serialized=None)"

        name = f"RETRIEVER_{(serialized_name).upper()}"
        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, name) # Corrected call
        if not trace_client: return

        inputs = {'query': query, 'tags': tags, 'metadata': metadata, 'kwargs': kwargs, 'serialized': serialized}
        self._start_span_tracking(trace_client, run_id, parent_run_id, name, span_type="retriever", inputs=inputs)

    def on_retriever_end(self, documents: Sequence[Document], *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "RetrieverEnd") # Corrected call
        if not trace_client: return
        doc_summary = [{"index": i, "page_content": doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)]
        outputs = {"document_count": len(documents), "documents": doc_summary, "kwargs": kwargs}
        self._end_span_tracking(trace_client, run_id, outputs=outputs)

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
        serialized_name = serialized.get('name') if serialized else "Unknown (Serialized=None)"

        # --- Determine Name and Span Type ---
        span_type: SpanType = "chain"
        name = serialized_name if serialized_name else "Unknown Chain" # Default name
        node_name = metadata.get("langgraph_node") if metadata else None
        is_langgraph_root_kwarg = kwargs.get('name') == 'LangGraph' # Check kwargs for explicit root name
        # More robust root detection: Often the first chain event with parent_run_id=None *is* the root.
        is_potential_root_event = parent_run_id is None

        if node_name:
            name = node_name # Use node name if available
            if name not in self.executed_nodes: self.executed_nodes.append(name) # Leaving this in for now but can probably be removed
        elif is_langgraph_root_kwarg and is_potential_root_event:
             name = "LangGraph" # Explicit root detected
        # Add handling for other potential LangChain internal chains if needed, e.g., "RunnableSequence"

        # --- Ensure Trace Client ---
            # Pass parent_run_id to _ensure_trace_client
        trace_client = self._ensure_trace_client(run_id, parent_run_id, name) # Corrected call
        if not trace_client: return

        # --- Update Trace Name if Root ---
        # If this is the root event (parent_run_id is None) and the trace client was just created,
        # ensure the trace name reflects the graph's name ('LangGraph' usually).
        if is_potential_root_event and run_id == self._root_run_id and trace_client.name != name:
            trace_client.name = name # Update trace name to the determined root name

        # --- Start Span Tracking ---
        combined_inputs = {'inputs': inputs, 'tags': tags, 'metadata': metadata, 'kwargs': kwargs, 'serialized': serialized}
        self._start_span_tracking(trace_client, run_id, parent_run_id, name, span_type=span_type, inputs=combined_inputs)


    def on_chain_end(self, outputs: Dict[str, Any], *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, **kwargs: Any) -> Any:

        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "ChainEnd") # Corrected call
        if not trace_client: return

        span_id = self._run_id_to_span_id.get(run_id)
        # If it's the root run ending, _end_span_tracking will handle cleanup/save
        if not span_id and run_id != self._root_run_id:
            return # Don't call end tracking if it's not the root and span wasn't tracked

        # Prepare outputs for end tracking (moved down)
        combined_outputs = {"outputs": outputs, "tags": tags, "kwargs": kwargs}

        # Call end_span_tracking with potentially determined span_type
        self._end_span_tracking(trace_client, run_id, outputs=combined_outputs)

        # --- Root node cleanup (Existing logic - slightly modified save call) ---
        if run_id == self._root_run_id:
            if trace_client and not self._trace_saved:
                # Save might need to be async if TraceClient methods become async
                # Pass overwrite=True based on client's setting
                trace_id_saved, trace_data = trace_client.save(overwrite=trace_client.overwrite)
                self.traces.append(trace_data) # Leaving this in for now but can probably be removed
                self._trace_saved = True
                # Reset tracer's active client *after* successful save
                if self.tracer._active_trace_client == trace_client:
                    self.tracer._active_trace_client = None 
            
            # Reset root run id after attempt
            self._root_run_id = None
            # Reset input storage for this handler instance

    def on_chain_error(self, error: BaseException, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:
        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "ChainError") # Corrected call
        if not trace_client:
            return

        span_id = self._run_id_to_span_id.get(run_id)
        
        # Let _end_span_tracking handle potential root run cleanup
        if not span_id and run_id != self._root_run_id:
            return

        self._end_span_tracking(trace_client, run_id, error=error)

    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, inputs: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any:
        name = serialized.get("name", "Unnamed Tool") if serialized else "Unknown Tool (Serialized=None)"

        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, name) # Corrected call
        if not trace_client: return

        combined_inputs = {'input_str': input_str, 'inputs': inputs, 'tags': tags, 'metadata': metadata, 'kwargs': kwargs, 'serialized': serialized}
        self._start_span_tracking(trace_client, run_id, parent_run_id, name, span_type="tool", inputs=combined_inputs)

        # --- Track executed tools (remains the same) ---
        if name not in self.executed_tools: self.executed_tools.append(name) # Leaving this in for now but can probably be removed
        parent_node_name = None
        if parent_run_id and parent_run_id in self._run_id_to_span_id:
            parent_span_id = self._run_id_to_span_id[parent_run_id]
            parent_node_name = trace_client.span_id_to_span[parent_span_id].function

        node_tool = f"{parent_node_name}:{name}" if parent_node_name else name
        if node_tool not in self.executed_node_tools: self.executed_node_tools.append(node_tool) # Leaving this in for now but can probably be removed
        # --- End Track executed tools ---


    def on_tool_end(self, output: Any, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:
        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "ToolEnd") # Corrected call
        if not trace_client: return
        outputs = {"output": output, "kwargs": kwargs}
        self._end_span_tracking(trace_client, run_id, outputs=outputs)

    def on_tool_error(self, error: BaseException, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:

        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "ToolError") # Corrected call
        if not trace_client: return
        self._end_span_tracking(trace_client, run_id, error=error)

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, invocation_params: Optional[Dict[str, Any]] = None, options: Optional[Dict[str, Any]] = None, name: Optional[str] = None, **kwargs: Any) -> Any:

        llm_name = name or serialized.get("name", "LLM Call")

        trace_client = self._ensure_trace_client(run_id, parent_run_id, llm_name) # Corrected call
        if not trace_client: return
        inputs = {'prompts': prompts, 'invocation_params': invocation_params or kwargs, 'options': options, 'tags': tags, 'metadata': metadata, 'serialized': serialized}
        self._start_span_tracking(trace_client, run_id, parent_run_id, llm_name, span_type="llm", inputs=inputs)

    def on_llm_end(self, response: LLMResult, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:

        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "LLMEnd") # Corrected call
        if not trace_client:
            return
        outputs = {"response": response, "kwargs": kwargs}
        # --- Token Usage Extraction and Accumulation ---
        token_usage = None
        prompt_tokens = None  # Use standard name
        completion_tokens = None # Use standard name
        total_tokens = None
        if response.llm_output and isinstance(response.llm_output, dict):
            # Check for OpenAI/standard 'token_usage' first
            if 'token_usage' in response.llm_output:
                token_usage = response.llm_output.get('token_usage')
                if token_usage and isinstance(token_usage, dict):
                    prompt_tokens = token_usage.get('prompt_tokens')
                    completion_tokens = token_usage.get('completion_tokens')
                    total_tokens = token_usage.get('total_tokens') # OpenAI provides total
            # Check for Anthropic 'usage'
            elif 'usage' in response.llm_output:
                token_usage = response.llm_output.get('usage')
                if token_usage and isinstance(token_usage, dict):
                    prompt_tokens = token_usage.get('input_tokens') # Anthropic uses input_tokens
                    completion_tokens = token_usage.get('output_tokens') # Anthropic uses output_tokens
                    # Calculate total if possible
                    if prompt_tokens is not None and completion_tokens is not None:
                        total_tokens = prompt_tokens + completion_tokens

            # --- Store individual usage in span output and Accumulate --- 
            if prompt_tokens is not None or completion_tokens is not None:
                # Store individual usage for this span
                outputs['usage'] = { 
                    'prompt_tokens': prompt_tokens,
                    'completion_tokens': completion_tokens,
                    'total_tokens': total_tokens
                }
            
        self._end_span_tracking(trace_client, run_id, outputs=outputs)
        # --- End Token Usage ---

    def on_llm_error(self, error: BaseException, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:

        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "LLMError") # Corrected call
        if not trace_client: return
        self._end_span_tracking(trace_client, run_id, error=error)

    def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], *, run_id: UUID, parent_run_id: Optional[UUID] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, invocation_params: Optional[Dict[str, Any]] = None, options: Optional[Dict[str, Any]] = None, name: Optional[str] = None, **kwargs: Any) -> Any:
        # Reuse on_llm_start logic, adding message formatting if needed
        chat_model_name = name or serialized.get("name", "ChatModel Call")
        # Add OPENAI_API_CALL suffix if model is OpenAI and not present
        is_openai = any(key.startswith('openai') for key in serialized.get('secrets', {}).keys()) or 'openai' in chat_model_name.lower()
        is_anthropic = any(key.startswith('anthropic') for key in serialized.get('secrets', {}).keys()) or 'anthropic' in chat_model_name.lower() or 'claude' in chat_model_name.lower()
        is_together = any(key.startswith('together') for key in serialized.get('secrets', {}).keys()) or 'together' in chat_model_name.lower()
        # Add more checks for other providers like Google if needed
        is_google = any(key.startswith('google') for key in serialized.get('secrets', {}).keys()) or 'google' in chat_model_name.lower() or 'gemini' in chat_model_name.lower()

        if is_openai and "OPENAI_API_CALL" not in chat_model_name:
            chat_model_name = f"{chat_model_name} OPENAI_API_CALL"
        elif is_anthropic and "ANTHROPIC_API_CALL" not in chat_model_name:
            chat_model_name = f"{chat_model_name} ANTHROPIC_API_CALL"
        elif is_together and "TOGETHER_API_CALL" not in chat_model_name:
            chat_model_name = f"{chat_model_name} TOGETHER_API_CALL"

        elif is_google and "GOOGLE_API_CALL" not in chat_model_name:
             chat_model_name = f"{chat_model_name} GOOGLE_API_CALL"

        trace_client = self._ensure_trace_client(run_id, parent_run_id, chat_model_name) # Corrected call with parent_run_id
        if not trace_client: return
        inputs = {'messages': messages, 'invocation_params': invocation_params or kwargs, 'options': options, 'tags': tags, 'metadata': metadata, 'serialized': serialized}
        self._start_span_tracking(trace_client, run_id, parent_run_id, chat_model_name, span_type="llm", inputs=inputs) # Use 'llm' span_type for consistency

    def on_agent_action(self, action: AgentAction, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:
        action_tool = action.tool
        name = f"AGENT_ACTION_{(action_tool).upper()}"
        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, name) # Corrected call
        if not trace_client: return

        inputs = {'tool_input': action.tool_input, 'log': action.log, 'messages': action.messages, 'kwargs': kwargs}
        self._start_span_tracking(trace_client, run_id, parent_run_id, name, span_type="agent", inputs=inputs)

    def on_agent_finish(self, finish: AgentFinish, *, run_id: UUID, parent_run_id: Optional[UUID] = None, **kwargs: Any) -> Any:
        # Pass parent_run_id
        trace_client = self._ensure_trace_client(run_id, parent_run_id, "AgentFinish") # Corrected call
        if not trace_client: return

        outputs = {'return_values': finish.return_values, 'log': finish.log, 'messages': finish.messages, 'kwargs': kwargs}
        self._end_span_tracking(trace_client, run_id, outputs=outputs)
